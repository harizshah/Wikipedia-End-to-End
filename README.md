# Wikipedia-End-to-End
Wikipedia Stadium Page

The first process kicked in with using Apache Airflow for extracting from the wikipedia website, processing and load to store data in the Azure Data Lake . Ensuring a seamless and automated workflow throughout. This step laid the foundation for a rich and diverse dataset essential for our analysis.

Beside that, storing this colossal dataset securely and efficiently was made possible through Azure Data Lake, providing scalability and reliability in handling large volumes of data, ensuring accessibility and security were at the forefront of our operations.

Seamlessly migrating this curated data using Azure Data Factory was a pivotal stage, facilitating the smooth flow of information, allowing us to harness the power of Azure Synapse for streamlined querying and analysis. One of the key component on using Azure Synapse is to do analysis like top 5 stadiums by capacity, stadium with closes capacity to regional median, stadiums with capacity above the average and more using SQL also Azure Synapse provided lightning-fast analytics, enabling us to derive actionable insights from our dataset.

Finally, the reason I put Tableau as my data visualization on this project as I want to try and learn the features from this app and it really helps me to visualizing our discoveries in Tableau, where our findings came to life! Transforming raw data into compelling visual narratives empowered
that can help visualizing the data using multiple pie chart and one of my favourite is geographical chart that can help stakeholders or people to understand and see where all the stadium are located.
